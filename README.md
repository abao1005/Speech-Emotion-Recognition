# Speech-Emotion-Recognition
首先非常感謝 https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer 此位網友之語音情緒辨識專案，  
讓踏入此領域的新手得以初步了解資料處理與模型搭建之過程。

## 動機
在自我介紹的時候，許多人都會提及自己的興趣是聽音樂，　　
的確，音樂佔據人類生活非常重要的地位，　　
它能振奮人心、能讓人共鳴流淚、能讓人放鬆、也能陪伴我們走過每個無聊、有趣的時刻。

但平時我們在挑選、聆聽歌曲的時候，總猶如一場賭博，　　
保守的困在喜愛歌單的舒適圈內，總覺一絲煩膩；　　
而跳脫守備範圍聽聽推薦曲目，卻又常聽得有些失望。

因此，我希望能利用語音情緒的辨識系統、大三專題時實作的曲風辨識模型，並找尋是否有人類情緒與特定曲風之適配性研究，  
三相結合，打造一款基於話者即時情緒來推薦其適當歌曲的暖心系統。

## 實作過程與結果
經過多次嘗試，仍無法達到原作者 70% 左右之 val_accuracy，　　 
使用原程式碼只得約 35% 之 val_accuracy，  　
並於約 100 個 epoch 後會開始 overfitting，  　
研究得知資料不足或是模型太過複雜皆有可能導致過擬合， 　 
因此嘗試加入幾層 dropout 層與 EarlyStopping 後，val_accuracy來到約 45% (辨識男性、女性各八種情緒，共16個labels)。

目前認為資料量仍嫌不足(僅1440個音檔)，且初步只使用1d-cnn，  
未來若能利用音檔頻譜圖，善用圖像辨識的強大模型，並增加資料集，應該可以在此準確率之上再行優化。

## 心得
從大三開始實作專題的過程就覺得，搭建模型，與了解相關名詞、概念的時候非常有趣，  
未來希望可以持續了解深度學習相關知識，挑選paper研讀，變的更加專業。
就算無法打造出一款State-of-art的模型，也希望自己可以認清、善用、並具備分析既有模型的能力，以解決日常生活遇到的大小困難！
